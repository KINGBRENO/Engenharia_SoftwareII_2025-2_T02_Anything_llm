# -*- coding: utf-8 -*-
"""modelo-Qwen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zWuxAdiRz9AQqnKo4Arehrjgsu3Hz3-P

Instala√ß√£o e importa√ß√£o de m√≥dulos
"""

#!pip install -q transformers torch accelerate

import os
import torch
import time
from transformers import AutoTokenizer, AutoModelForCausalLM
#from IPython.display import clear_output
#from google.colab import drive

"""Antes de prosseguir, verificar se est√° com a GPU habilitada. A infer√™ncia demora demais se estiver usando apenas CPU."""

print("GPU dispon√≠vel?", torch.cuda.is_available())

if not torch.cuda.is_available():
    print("Ative a GPU em Runtime -> Change runtime type -> T4 GPU.")

"""Carregando o modelo Qwen2.5-Coder-1.5B-Instruct do HuggingFace"""

model_id = "Qwen/Qwen2.5-Coder-1.5B-Instruct"

print(f"Carregando {model_id}...")
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    dtype=torch.float16,
    device_map="cuda"
)

"""Defini√ß√µes de fun√ß√µes √∫teis: **Gera√ß√£o de √°rvore de diret√≥rios a partir do reposit√≥rio clonado** e **fun√ß√£o de infer√™ncia** com prompt."""

def gerar_arvore_diretorios(caminho_raiz, max_depth=3, ignorar=['.git', 'node_modules', 'dist', 'build', 'coverage', 'venv', '.github', 'assets']):
    tree_str = ""
    root_level = caminho_raiz.count(os.sep)

    for root, dirs, files in os.walk(caminho_raiz):
        dirs[:] = [d for d in dirs if d not in ignorar]
        level = root.count(os.sep) - root_level
        if level > max_depth:
            continue

        indent = ' ' * 4 * level
        tree_str += f"{indent}{os.path.basename(root)}/\n"

        if level < max_depth:
            subindent = ' ' * 4 * (level + 1)
            for f in files[:10]:
                tree_str += f"{subindent}{f}\n"
            if len(files) > 10:
                tree_str += f"{subindent}... (+{len(files)-10} arquivos)\n"

    return tree_str

def extrair_resumo_readmes(repo_path, max_chars=2000):
    readmes_encontrados = ""

    locais_chave = [
        repo_path,
        os.path.join(repo_path, "server"),
        os.path.join(repo_path, "frontend"),
        os.path.join(repo_path, "collector")
    ]

    for pasta in locais_chave:
        caminho_arquivo = os.path.join(pasta, "README.md")

        if os.path.exists(caminho_arquivo):
            try:
                with open(caminho_arquivo, "r", encoding="utf-8", errors="ignore") as f:
                    conteudo = f.read()

                    conteudo = "\n".join([line for line in conteudo.splitlines() if line.strip()])

                    resumo = conteudo[:max_chars]

                    nome_pasta = os.path.basename(pasta)
                    if nome_pasta == os.path.basename(repo_path):
                        nome_pasta = "RAIZ DO PROJETO"

                    readmes_encontrados += f"\n--- CONTE√öDO DO README ({nome_pasta}) ---\n"
                    readmes_encontrados += resumo
                    readmes_encontrados += "\n... (conte√∫do truncado para economizar mem√≥ria)...\n"
            except Exception as e:
                print(f"Erro ao ler {caminho_arquivo}: {e}")

    return readmes_encontrados

def inferir_arquitetura_pela_tree(tree_text, prompt):
    messages = [
        {"role": "system", "content": "Voc√™ √© um especialista em an√°lise de c√≥digo e padr√µes arquiteturais."},
        {"role": "user", "content": prompt}
    ]

    inputs = tokenizer.apply_chat_template(messages, tokenize=True, return_dict=True, return_tensors="pt", add_generation_prompt=True).to(model.device)

    generated_ids = model.generate(
        **inputs,
        max_new_tokens=1024,
        temperature=0.2
    )

    return tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0].split("assistant")[-1].strip()

"""Clonando reposit√≥rio objeto da an√°lise"""

#!git clone https://github.com/Mintplex-Labs/anything-llm.git

"""Defini√ß√£o do prompt (en/pt)"""

prompt = """
Analise os artefatos abaixo de um reposit√≥rio de software:
1. A estrutura de pastas (Tree).
2. Trechos dos arquivos de documenta√ß√£o (READMEs).

TAREFA:
Classifique a arquitetura deste projeto escolhendo padr√µes arquiteturais que se encaixem a ele
(ex.: Camadas, Pipe-and-Filters, Client-Server, Peer-to-Peer, Microservices, Blockchain, SOA, Publish-Subscribe, Shared-Data, Blackboard).

IMPORTANTE:
Voc√™ DEVE fornecer 5 palpites diferentes, com uma porcentagem de confian√ßa para cada um.

Siga ESTRITAMENTE este formato de resposta:

1. [Nome do Padr√£o] - [XX]%
   Justificativa: [Explica√ß√£o baseada em pastas espec√≠ficas]

2. [Nome do Padr√£o] - [XX]%
   Justificativa: [...]

(Repita at√© o 5)

--- IN√çCIO DA TREE ---
{}
--- FIM DA TREE ---

--- IN√çCIO DOS READMES ---
{}
--- FIM DOS READMES ---
"""

"""Por fim, executamos o modelo e esperamos pelo resultado da an√°lise (aprox. 40s)"""

repo_path = "./anything-llm"
tree_visual = gerar_arvore_diretorios(repo_path)
readmes_content = extrair_resumo_readmes(repo_path)

print(f"Estrutura capturada (primeiras 10 linhas):\n{'\n'.join(tree_visual.splitlines()[:10])}...\n")

print("Aguardando an√°lise do modelo...")

# Caminho absoluto onde o script est√°
base_dir = os.path.dirname(os.path.abspath(__file__))

# Pastas finais
entradas_dir = os.path.join(base_dir, "entradas")
respostas_dir = os.path.join(base_dir, "respostas")

# Garantir que existem
os.makedirs(entradas_dir, exist_ok=True)
os.makedirs(respostas_dir, exist_ok=True)

for a in range(1, 5):
    start = time.perf_counter()
    
    resultado = inferir_arquitetura_pela_tree(
        tree_visual,
        prompt.format(tree_visual, readmes_content)
    )
    
    end = time.perf_counter()
    tempo_execucao = end - start

    # Caminhos corretos para os arquivos
    input_path = os.path.join(entradas_dir, f"entrada{a}.txt")
    output_path = os.path.join(respostas_dir, f"resposta{a}.txt")

    # Salvar entrada
    with open(input_path, 'w', encoding='utf-8') as f:
        f.write(tree_visual)
        f.write(readmes_content)

    # Salvar resposta
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(f"TEMPO_DE_EXECUCAO={tempo_execucao}\n")
        f.write(resultado)

    print(f"üü¢ Salvo: {output_path}")